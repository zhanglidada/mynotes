# 一.数值转换和数据的表示
## 1.数值转换
### 十进制转换为其他进制
一般采用短除法

### 二进制和十六进制互转
二进制转为16进制
四位一组，每组转换为对应的16进制符号

16进制转为2进制
每位16进制转为四位的对应二进制数



## 2.计算机内数据的表示（真值与机器数）

### 2.1 原码、反码、补码、移码


移码：
在补码的基础上将符号位取反，但是移码只能用于表示整数

![[软考/中级/图片/Pasted image 20250914160923.png]]

### 2.2 定点数和浮点数
#### 定点数：
定点数就是小数点的位置固定不变的数。小数点的位置通常有两种约定方式，分别是定点整数和定点小数。

定点整数：
纯整数，小数点在最低有效数值位之后

定点小数：
纯小数，小数点在最高有效数值位之前

#### 浮点数
浮点数就是小数点位置不固定的数，它能表示更大范围的数。

浮点数通常表示为$N = M \cdot R^e$，其中 M称为尾数，R 称为基数，E 称为阶码。
阶码决定浮点数所能表示的数值范围，尾数决定浮点数所能表示的数值精度。


### 2.3校验码

#### 码距：
一个编码系统中任意两个码字之间不同的二进制位数，也称为海明距离。计算方法是对两个码字之间进行异或操作，并统计结果中 1 的个数。

在一个有效编码集中任意两个码字的最小码距称为该编码集的海明距离。

码距的检测和纠错距离：
若码距为 d，可保证检测出 ≤ d−1 位错误
若码距为 d，可纠正 ≤ ⌊(d−1)/2⌋ 位错误。

快速理解：码距就是一个编码系统中，有多少位必须反转才能让 A 变成 B

对于检测和纠错，其实就是对于收到的编码信息，判断是否同编码系统中的字匹配，如果匹配就正确，如果不匹配就观察错误的字同编码系统中的哪个字更像，并根据码距去判断是否可以纠错。

对于匹配的时候，可能出错的位数已经超过了码距，此时虽然能匹配某个字，但是实际信息也是错误的。


#### 奇偶校验码：
校验码用来检测传输的数据是否出错。校验码中应用比较多的一般是奇偶校验码和循环冗余校验码两种。

通过在编码中增加一位校验位来使编码中1 的个数为奇数(奇校验)或者为偶数(偶校验)，从而使码距变为 2。

对于奇校验，它可以检测编码中奇数位出错的情况，但不能发现偶数位出错的情况。当编码中存在 0-> 1 / 1 -> 0 的情况，此时编码中奇数的个数发生了变化，此时可以检测到编码发生了错误。对于偶校验原理类似。


#### 循环冗余校验码：
循环冗余编码 CRC 广泛用于数据通信领域和磁介质存储系统中，它利用生成多项式为 K 个数据位产生 R个校验位来进行编码，其编码长度为 K + R。

#### 海明码
海明码的构成方法：在数据位之间插入 k 个校验码，通过扩大码距来实现检错和纠错。

设数据是 n 位，校验位是 k 位，则 n 和 k 必须满足以下关系：$2^k-1 >= n + k$


# 二 计算机系统的组成、指令和输入系统

## 2.1 计算机系统组成

冯诺伊曼计算机的结构：
冯·诺依曼计算机结构（Von Neumann Architecture）是现代计算机体系的基础，其核心思想是**​“存储程序”​**和**​“程序控制”​**
![[Pasted image 20250915072609.png]]


存储程序：
指令和数据混放在同一块可读写的随机存储器中，cpu 通过地址访问存储器中的指令和数据，程序只需要读取到内存中就能运行。

地址空间统一：
内存，寄存器，显存全部映射到同一套地址编号，cpu 用同一套 load ，store 指令就能访问任何东西

指令顺序执行：
指令按存储器中的顺序依次执行，通过**程序计数器（PC）​**指向当前指令地址，执行后自动递增。特殊情况下（如分支跳转）可修改PC值

二进制与运算-控制分离：
信息全部二进制；控制器把“操作信号”从“运算部件”里单独拎出来，通过操作码（Opcode）和操作数（Operand）区分功能。例如，操作码`0000`表示加法，操作数`0101`表示操作数地址

**工作原理：**
取指(Fetch)从存储器中读取下一条指令到控制器。
译码(Decode)​解析指令的操作码和操作数。
​执行(Execute)​运算器执行操作（如数据运算或内存访问）。
写回(Write-back)​将结果写入寄存器或存储器

执行加法指令`ADD R1, R2, R3`时，控制器先取指令，译码确定需将寄存器R2和R3的值相加，运算器执行加法后，结果存入R1


冯·诺依曼把“程序”变成了普通数据，把“硬件”变成了可无限替换的模块；
只要 PC 还在自动加一、内存还按地址取字节，我们就仍活在冯·诺依曼的宇宙里



**主存储器：**

MAR：地址寄存器，用来存放当前CPU访问的内存单元地址

MDR：数据寄存器，用来存入内存中读入/写出的信息。

**运算器：**
ACC：累加器，用于存放操作数或者运算结果

MQ：乘商寄存器，在乘、除运算时用于存放操作数或运算结果

X：通用的操作数寄存器，用于存放操作数

ALU：算数逻辑单元，内部有复杂的电路实现算数运算和逻辑运算

DR：数据缓存寄存器

PSW：状态条件寄存器，用来保存指令运行标志


**CPU 控制器：**

CU：控制单元，分析指令并给出控制信号

IR：指令寄存器，<font color=red>存放当前执行的指令</font>

PC：程序计数器，<font color=red>存放下一条指令的地址</font>，自动+1

AR：地址寄存器，保存当前 cpu 所访问的内存单元地址

ID：指令译码器，对操作码进行分析



## 2.2 指令系统

一条指令就是机器语言的一个语句，它是一组有意义的二进制代码
一条指令通常包括操作码字段和地址码字段两个部分

### 2.2.1 CPU的七种寻址方式
寻找指令中操作数有效地址的方式称为寻址方式。

**1）立即(数)寻址:**
操作数与操作码一起放在代码段区域，直接写在指令中并<font color=red>作为指令的一部分</font>。这种操作数称为立即数，寻址方式也被称为立即数寻址。

**立即数寻址方式通常用来给寄存器赋初值。**

```
MOV AL, 05H （8位立即数）  
MOV DX, 8000H （16位立即数）
```

**2）寄存器(直接)寻址:**
指令需要的操作数存放在 CPU 内部寄存器中，例如 AX、BX、CX、DX 等。寄存器寻址方式减少了读/写存储器单元的次数，所以**使用寄存器寻址方式的指令一般执行速度比较快。**

```
MOV DS, AX
MOV AL, BL
```


**3）(存储器)直接寻址:**
操作数存放在存储器(内存)中，在指令中给出的是该操作数的有效地址EA(段内偏移地址)。操作数通常存放在数据段中，默认的段地址存放在 DS 段寄存器中。

操作数的内存地址：**DS 段地址 ×16(左移 4 位)+16 位偏移地址=20 位内存地址**。

```
MOV BX, [2000H] (假设段地址 DS=1000H)  
内存地址：1000H×16+2000H=12000H
```

**4）寄存器间接寻址:**
操作数存放在存储器中(内存中)，有效地址（端内偏移地址）存放在内部寄存器SI，DI，BX，BP中，段地址可以放在SS或DS中。

- 若段内偏移地址存放于 SI、DI、BX 之一中，默认段地址存放在 DS 寄存器中。

```
MOV AX, [SI]MOV AX, [DI]MOV AX, [BX]
```

操作数的内存地址：**DS 段地址 ×16(左移 4 位)+ [SI]/[DI]/[BX] 偏移地址 = 20 位内存地址。**

- 若段内偏移地址存放于 BP 中，默认段地址存放在寄存器 SS(堆栈段)中。

```
MOV BX, [BP]
```

操作数的内存地址：**SS 段地址 ×16(左移 4 位)+ [BP] 偏移地址=20 位内存地址。**

**5）寄存器相对寻址:**
操作数存放在存储器（内存）中，有效地址（段内偏移地址）存放在内部寄存器SI，DI，BX，BP中，段地址放在SS或DS中。

相比于寄存器间接寻址方式，寄存器相对寻址的不同之处在于多了一个 8 位或 16 位的带符号常数偏移量。

```
MOV AL, [SI-200H]
```

操作数的内存地址：**SS 或 DS 段地址 ×16(左移 4 位)+ [BP]/[SI]/[DI]/[BX]偏移地址+常数偏移量 = 20 位内存地址。**

```
MOV AL, [SI-2]    (假设 DS=3000H,SI=1000H)内存地址：3000H×16+1000H-2=30FFEH
```


**6）基址、变址寻址:**
操作数存放在存储器(内存)中，基址存放在内部寄存器BX或BP中，变址存放在内部寄存器 SI或DI中。由于段地址存放在内部寄存器 SS、DS 之一中，所以也可分为两类，类比寄存器间接寻址方式即可。

操作数内存地址：**SS 或 DS 段地址 ×16(左移 4 位)+[BP]或[BX]基址+[SI][di]变址=20 位内存地址**

```
MOV AL, [BP][DI]    (假设 SS=8000H,BP=1000H,DI=0500H)内存地址：8000H×16+1000H+0500H=81500H
```


**7）基址、变址相对寻址:**
操作数存放在存储器(内存)中，基址存放在内部寄存器 BX或BP中，变址存放在内部寄存器 SI或DI中。由于段地址存放在内部寄存器 SS或DS中，所以也可分为两类，类比寄存器间接寻址方式即可。

相比于基址、变址寻址方式，基址、变址、相对寻址的不同之处在于多了一个 8 位或 16 位的带符号常数偏移量。

```
MOV AL, 1000H[BP][DI]
```

操作数内存地址：**SS 或 DS 段地址 ×16(左移 4 位)+[BP]或[BX]基址+[SI][di]变址+常数偏移量=20 位内存地址**

```
MOV AL, 0010H[BX][SI]  (假设 DS=6000H,BX=5000H,SI=0300H)内存地址：6000H×16+5000H+0300H+0010H=65310H
```


### 2.2.2指令集分类

指令集分为复杂指令集 CISC 和精简指令集 RISC

## 2.3流水线

### 1）概念
流水线将指令拆分成多个独立阶段，让多条指令在不同阶段并行处理，目的是提高cpu的吞吐率和整体执行性能。

### 2）阶段划分

流水线将单条指令的执行拆分为多个步骤，典型阶段包括：

**取指（Fetch）​**​：从指令缓存中读取指令

​**译码（Decode）​**​：解析指令操作码和操作数

**执行（Execute）​**​：完成算术/逻辑运算

**访存（Memory Access）​**​：处理数据加载/存储

**写回（Write Back）​**​：将结果写入寄存器或内存
    
例如，Intel 486首次采用五级流水线（取指→译码→转址→执行→写回）

不同指令的各阶段操作可重叠执行。例如，当第一条指令进入译码阶段时，第二条指令即可开始取指，形成类似工厂装配线的流水作业。


### 3）计算

**流水线周期：**
流水线周期为流水线为执行时间最长的一段，因为需要保证在一个周期内可以执行完流水线中任意一个阶段。

**流水线计算公式：**
流水线执行时间是指完成n条指令所需的总时间。

流水线执行时间 = 第1条指令的执行时间 + （指令条数 - 1） * 流水线周期

也就是说，除了第一条指令需要完整的执行时间外，其余指令都只需要等待流水线周期时间即可开始执行

### 4）吞吐率和加速比
**流水线吞吐率（TP）：**
单位时间内完成的指令条数，计算公式为：TP = 指令条数 / 流水线执行时间

反应了流水线的处理能力和效率，当指令条数无穷大时 $TP \approx 1/Δt$


**流水线加速比：**
加速比是指完成同一批任务时，不使用流水线技术与使用流水线技术所需时间之比。计算公式为：S = 不使用流水线执行时间 / 使用流水线执行时间。

加速比越大，说明流水线技术带来的性能提升越明显。

### 5）流水线效率
流水线效率是指流水线实际产出与其最大产出之间的比率

### 6）实力分析：
假设某计算机系统需要执行100条指令，每条指令的执行过程包括取指（2ms）、分析（4ms）和执行（1ms）三个阶段。根据流水线技术的计算公式：

- **流水线周期** = 4ms（取最长时间段）
- **理论流水线执行时间** = 2ms + 4ms + 1ms + (100 - 1) × 4ms = 403ms
- **实际流水线执行时间**（考虑复杂性）可能略大于理论值，如408ms
- **吞吐率** = 100 / 403 ≈ 0.248（或根据实际执行时间计算）
- **加速比**（假设不使用流水线每条指令需顺序执行，总时间为700ms） = 700ms / 403ms ≈ 1.74


## 2.4 输入输出（CPU和外设之间的数据传输方式）

### 2.4.1 程序控制方式

程序控制方式是指CPU与外设间的数据传送是在程序的控制下完成的一种数据传送方式。分为无条件传送方式和查询传送方式两种。

1）无条件传送方式
所谓无条件，就是假设外设已处于就绪状态，数据传送时，程序就不必再去查询外设的状态，而直接执行I/O指令进行数据传输。


2）查询传送方式
查询传送方式在传送数据前先查询外设的状态，当外设准备好时，CPU执行I/O指令传送数据；若未准备好时，则CPU等待。

要求CPU与外设间的接口电路需要两个端口：数据端口和状态端口。

优点：能较好地协调外设与CPU之间的定时关系，因而比无条件传送方式容易实现准确传送。

缺点:该方式需要不断查询外设的状态，大量时间花在等待循环中，当主机与中、低速外设交换信息时，大大降低了CPU利用率。

### 2.4.2 中断方式
中断传送方式是指当外设需要与CPU进行信息交换时，由外设向CPU发出请求信号，使CPU暂停正在执行的程序，转去执行数据的输入/输出操作，数据传送结束后，CPU再继续执行被暂停的程序。   

优点：CPU不必查询等待，工作效率高，CPU与外设可以并行工作；由于外设具有申请中断的主动权，故系统实时性比查询方式要好得多。

缺点：采用中断传送方式的接口电路相对复杂，而且，每进行一次数据传送就要中断一次CPU。CPU每次响应中断后，都要转去执行中断处理程序，要进行断点和现场的保护和恢复，浪费了很多CPU的时间。故这种传送方式一般适合于少量的数据传送。

### 2.4.3 DMA方式
DMA控制器从CPU完全接管对总线的控制，数据交换不经过CPU，而直接在内存和I/O设备之间进行。

DMA传送方式需要一个专用接口芯片DMA控制器（DMAC）对传送过程加以控制和管理。进行DMA传送期间，CPU放弃总线控制权，将系统总线交由DMAC控制，由DMAC发出地址以及读/写信号来实现高速数据传输。传送结束后DMAC再将总线控制权交还给CPU。

DMAC中主要包括一个控制状态寄存器、一个地址寄存器和一个字节计数器，在传送开始前先要对这些寄存器进行初始化，一旦传送开始，整个过程便全部由硬件实现。

DMA方式的工作过程是： CPU 接收到I/O 设备的DMA 请求时，它给I/0 控制器发出一条命令，启动DMA 控制器，然后继续其他工作。之后CPU 就把控制操作委托给DMA 控制器，由该控制器负责处理。DMA 控制器直接与存储器交互，传送整个数据块，每次传送一个字，这个过程不需要CPU 参与。传送完成后，DMA 控制器发送一个中断信号给处理器。因此只有在传送开始和结束时才需要CPU的参与(预处理【设置CR、MAR、DC等】和后处理【中断处理、唤醒因该I/O阻塞的进程程等】)。


优点:传送速率很高，这对高速度大批量数据传送特别有用。

缺点:要求设置DMA控制器，电路结构复杂，硬件开销大
### 2.4.4 IO处理机(考察不多)

I/O 处理机（I/O Processor），也称为外围处理机（Peripheral Processor），是一种专门负责输入/输出操作的处理机，是DMA方式的发展。

它可以进一步减少CPU的干预，即把对一个数据块的读（或写）为单位的干预，减少为对一组数据块的读（或写）及有关控制和管理为单位的干预。同时，又可以实现CPU、通道和I/0 设备三者的并行操作，从而更有效地提高整个系统的资源利用率。

**工作流程：**
接收请求：CPU 发送 I/O 请求到 I/O 处理机。

执行操作：I/O 处理机接收请求后，执行相应的 I/O 操作，包括数据传输和处理。

返回结果：操作完成后，I/O 处理机将结果返回给 CPU。

继续执行：CPU 在接收到结果后，可以继续执行其他任务。

**与其他 I/O 控制方式的比较：**
与通道方式相比：I/O 处理机的功能更强大，结构更接近于一般处理机。

与 DMA 方式相比：DMA 方式虽然减少了 CPU 的干预，但 I/O 处理机提供了更复杂的处理能力。


# 三 存储系统，总线系统和磁盘阵列
## 3.1 存储系统

### 3.1.1 层次结构

![[Pasted image 20250924210821.png]]


**层次结构中的两套系统：**
1）主存<-->辅存：实现虚拟存储系统，解决了主存容量不足的问题，由硬件 + 操作系统实现。

2）cache <-->主存：解决了主存与 cpu 速度不匹配的问题，由硬件自动完成。
cache 中存储的是主存中部分数据的复制，用于加速 cpu 对内存中数据的获取

![[Pasted image 20250921120818.png]]

**设计原则：**
1）局部性原理：
- 时间局部性：最近访问过的数据，短期内可能再次被访问（如循环变量）；  
- 空间局部性：访问某一数据时，其相邻数据也可能被访问（如数组遍历）。  

这一原理确保了“将近期访问的数据存放在高速缓存中”是高效的策略

2）性价比平衡：  
- 高速存储（如缓存）成本高、容量小，适合存放少量热数据；  
- 低速存储（如硬盘）成本低、容量大，适合存放大量冷数据。  

层次结构通过组合不同类型的存储设备，在“速度”与“容量”之间取得最优性价比。
### 3.1.2 分类


1）按层次进行分类
![[Pasted image 20250921120846.png]]
2）按传输介质进行分类
- 半导体存储：
	原理：利用半导体器件（如晶体管）的导通/截止状态存储数据（0/1）。

	类型：
		volatile（易失性）：断电后数据丢失，如DRAM（动态随机存取存储器，比如**内存**）、SRAM（静态随机存取存储器比如 **cache**）；
		non-volatile（非易失性）：断电后数据保留，如Flash（闪存或者**固态**）、ROM（只读存储器比如**主板上的 bios 写在 ROM 上**）；
		
	特点：速度快（纳秒级）、功耗低、体积小，是缓存和内存的核心介质。

![[Pasted image 20250921143232.png]]


- 磁表面存储器： 利用磁性材料的磁化方向（正向/反向）存储数据；  
	- 类型：硬盘（HDD）、软盘（已淘汰）、磁带；  
	- 特点：容量大（TB级）、成本低、速度慢（毫秒级）、寿命长，适合辅助存储。
- 光存储器
	- 原理：利用激光在光盘表面烧蚀凹坑（或改变反射率）存储数据；  
	- 类型：CD、DVD、蓝光光盘（BD）；  
	- 特点：成本低、便携性好、速度慢，主要用于数据分发和归档。

3）按存取方式进行分类

- 相联存储器：一种特殊的存储器读取方式，它允许通过内容（Content）或标签（Tag）直接访问存储单元，而不仅仅是通过地址访问
	向相联存储器写入信息时按顺序写入，不需要地址。读出时，要求CPU给出一个相联关键字，用它和存储器中所有单元中的一部分信息进行比较，若它们相等，则将此单元中余下的信息读出。

- 随机存取存储器（RAM）：读写任何一个存储单元所需的时间都相同，与位置无关。（SRAM用于L1/L2缓存，DRAM用于主存）

- 直接存取存储器（DAM）：既有随机存取特性，也有顺序存取特性。先直接选取信息所在区域，然后按顺序方式进行存取。（机械硬盘）

- 顺序存取存储器（SAM）：读写一个存储单元所需的时间取决于存储单元所在的位置。（磁带）

- 只读存储器（ROM）：正常工作时只能读取，不能写入（或写入难度大），在存储BIOS、固件等固定程序会使用。

顺序存取存储器和直接存取存储器都归为串行访问存储器（读取时间和数据位置有关）。

4）按信息的可更改性进行分类

- 读写存储器：可读可写（如内存、闪存、机械硬盘等）
- 只读存储器：只能读，不能写（如电影使用的光碟）


### 3.1.3 高速缓存 cache（重点！）

#### 3.1.3.1简介：
#### cache 的组成：

**缓存行 Cache Line** 是缓存中的最小单位（cache 的行和块是一个意思）。CPU Cache 被划分成多个组Set，每个Set中还可以有多个行Cache Line，**需要注意Cache Line是CPU Cache中的基本缓存单位**，也被称为**块**（Block），每次读写是以`Cache Line`为单位，一块块地去读取。

![[Pasted image 20250921173954.png]]
CPU cache Line 由有**效标志Valid**、**Tag**、**数据块Data**这3个部分组成。其中 valid 表示当前缓存的数据是否有效，tag用来表示查找Cache Line的各种标志并存储这片连续数据的公共地址，data是真正要来缓存一片连续内存地址中的数据。


看一下 cpu cache 的整体结构：

![[Pasted image 20250921174407.png]]

这里一个 set 表示一组 cpu cache line。

#### 3.1.3.2cache 的三种地址映射：
**1）直接映射(direct-mapped)：**
![[Pasted image 20250923214921.png]]

**在内存块和缓存块之间建立起固定的映射关系，一个内存块总是映射到同一个缓存块上**

- 将内存块索引对 Cache 块个数取模，得到固定的映射位置。例如 13 号内存块映射的位置就是 13 % 8 = 5，对应 5 号 Cache 块；
- 由于取模后多个内存块会映射到同一个缓存块上，产生块冲突，所以需要在 Cache 块上增加一个 **组标记（TAG）**，标记当前缓存块存储的是哪一个内存块的数据。其实，组标记就是内存块索引的高位，而 Cache 块索引就是内存块索引的低 4 位（8 个字块需要 4 位）；
- 由于初始状态 Cache 块中的数据是空的，也是无效的。为了标识 Cache 块中的数据是否已经从内存中读取，需要在 Cache 块上增加一个 **有效位（Valid bit）** 。如果有效位为 1，则 CPU 可以直接读取 Cache 块上的内容，否则需要先从内存读取内存块填入 Cache 块，再将有效位改为 1。


优点：查找效率高，硬件设备简单，地址变换速度快。

缺点：由于每个主存块只有一个固定位置可存放，即使Cache中别的Line空着也不能占用，无法充分利用Cache空间，这样冲突概率较大。如果冲突了，这多个内存块会**不断地交替装入**固定的映射Cache Line中，导致缓存命中率降低，所以**直接映射适合大容量Cache**


**2）全相连映射(fully associative)：**
![[Pasted image 20250923215417.png]]
**允许内存块映射到任何一个 Cache 块上。** 这种方式能够充分利用 Cache 的空间，块冲突率也更低，但是所需要的电路结构物更复杂，成本更高。

具体方式：

- 1、当 Cache 块上有空闲位置时，使用空闲位置；
- 2、当 Cache 被占满时则替换出一个旧的块腾出空闲位置；
- 3、由于一个 Cache 块会映射所有内存块，因此组标记 TAG 需要扩大到与主内存块索引相同的位数，而且映射的过程需要沿着 Cache 从头到尾匹配 Cache 块的 TAG 标记。


优点：映射方式比较灵活，**Cache的利用率高，块冲突的概率低**，只有当所有的Line都被占满后才会出现冲突。

缺点：访问缓存时，每次都要和全部Line中的内存进行比较，速度低延迟高是它无法避免的缺点，因此**适合于小容量Cache采用。**


**3）组相连映射(set-associative )：**
![[Pasted image 20250923215433.png]]

**组间采用直接映射，组内采用全相联映射。** 组相联映射是直接映射和全相联映射的折中方案，将 Cache 分为多组，<font color=red>每个内存块固定映射到一个特定分组中，同时又允许该内存块映射到该组内的任意 Cache 块中。</font>

上图中 cache 分为 2 组，每一组内四个 cache line，即 4 路组相连。

当查找缓存时，不再需要全部进行遍历，只需先查到cache的组号，然后在那一组内，进行小范围遍历。这样冲突概率较小，同时命中率较高，所以这种方式在现代的处理器中得到了广泛的应用。

#### 3.1.3.3 cache 的寻址方式：
以 intel 的 cpu 举例，Intel多数处理器的 L1 Cache 都是 32KB，8路组相联，Cache Line 是 64 Byte，可以得出 Cache Line 的条数 = 32KB / 64 = 512，也就是有 512 条 cache line。那么每一路的 Cache Line 数量为  512 / 8 = 64 ，也就是每一组或者每一Set的 Cache Line 个数为 64。

我们可以得到，每一Set的容量大小 = 64 x 64B= 4096B = 4KB，正好是一个内存页page的大小！


**内存地址的分解：**

内存地址被分成了3部分：`tag, set index 和 block offset`

1）tag：与Cache Line中的tag匹配, 内存地址的前 24位

2）set index：set索引，用来寻找定位Set。内存地址中间的6个bit表示 set index。

3）block offset：块偏移量，用来寻找Cache Line里data中的内存数据，用内存地址最后6位表示。

**Cache寻址步骤：**
1）先根据`set index`来找到对应的Set

2）接着根据tag在上一步找到的set中找到对应的`Cache Line`,如果找到且cache line 上对应的有效位`valid`为1，表示缓存命中；反之无论其中的tag和`Cache Line` 里的数据内容是什么，CPU 都会直接访问主存并重新加载数据 (当然这里涉及到缓存一致性的问题)。如果没找到，说明当前发生cache缺失，即`cache miss`，此时cpu 会访问内存，获取数据的同时将内容填充到缓存中

3）最后根据`block offset`在上一步找到的Cache Line的data中找到对应内存的数据
![[Pasted image 20250922215847.png]]

4）cache 性能分析
命中率：
![[Pasted image 20250923073316.png]]

平均访问时间：
![[Pasted image 20250923073154.png]]
访问效率：
访问效率e是指cache 的访问时间与平均访问时间的比值，反映了系统的存取效率，r为主存慢于cache的倍率。

`r=tm/tc`

`e=tc/ta=tc/[htc+(1-h)tm]=1/[h+(1-h)r]=1/[r+(1-r)h]`


#### 3.1.3.4 主存的扩展：

- 地址线：地址线用于获取数据的存储单元的位置，也决定可以存放多少个存储单元。
- 数据线：数据线表示一次地址访问可以访问多少位的数据。


1）位扩展：储单元个数不变，**每个存储单元包含的数据位数（字长）增加**
![[Pasted image 20250926072442.png]]

2）字扩展：每个存储单元中存储的数据位数不变，但是存储单元的个数增加

![[Pasted image 20250926072913.png]]

**低位的地址线与各存储芯片的地址线并联，多余的高位地址线用来产生相应的片选信号。**

3）字位扩展：将字扩展和位扩展结合起来，存储单元的个数和每个存储单元内存储数据的位数都增加。

扩展方法：
先扩展位宽，形成满足位要求的存储芯片组，再对芯片组进行字扩展，也就是**先变宽，再变长。**

![[Pasted image 20250926073848.png]]

#### 3.1.3.5 虚拟存储器：
1）定义
- 虚拟存储器是一种计算机内存管理技术，它将计算机系统中的**物理内存和磁盘空间结合起来**，形成一个虚拟的内存空间，使得应用程序可以访问比物理内存更大的内存空间。虚拟存储器的实现需要操作系统的支持，它通过将**内存中的数据分成若干个页面（或称为页）**，并将这些页面映射到磁盘上的页面文件中，从而实现了内存和磁盘之间的数据交换。

2）特征
- 多次性：
    无需在作业运行时一次性全部装入内存，而是允许被分成多次调入内存。
    
    对应传统的一次性。
    
- 对换性：
    在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入、换出。  
    
    对应传统的驻留性。
    
- 虚拟性：从逻辑上扩充了内存的容量，使用户看到的内存容量，远大于实际的容量。

#### 3.1.3.5 磁盘存储器：

存取时间 = 寻道时间 + 等待时间（平均定位时间 + 转动延迟）


## 3.2 总线系统
### 3.2.1 片内总线（内部总线）
芯片内部总线，是cpu芯片内部寄存器与寄存器之间、寄存器与ALU之间的公共连接总线。

### 3.2.2 系统总线

系统总线是计算机系统各功能部件（CPU，主存，IO接口）之间互相连接的总线。可以分为数据总线，地址总线和控制总线三种。

### 3.3.3 通信总线（外部总线）

用于设备一级的互联，计算机可以通过该总线和其他设备进行信息与数据交换

## 3.3 磁盘阵列技术（RAID）

RAID （ Redundant Array of Independent Disks ）即独立磁盘冗余阵列，简称为「磁盘阵列」，其实就是用多个独立的磁盘组成在一起形成一个大的磁盘系统，从而实现比单块磁盘更好的存储性能和更高的可靠性。

![[Pasted image 20251004230047.png]]

## 3.4 计算机可靠性
计算机可靠性指的是从它开始运行t0，到某个时刻t1这段时间内能正常运行的概率，用R(t)表示。

串联部件的可靠性：各个部件可靠性的乘积

并联部件的可靠性：1 - 各个部件失效性的乘积


# 二.数据结构和算法
## 2.1基本概念
程序 = 数据结构 + 算法

算法的五个特性：有穷性、确定性、可行性、输入、输出

算法效率的度量：时间复杂度 + 空间复杂度

时间复杂度：
时间开销与问题规模n 之间的关系

空间复杂度：
空间开销（内存开销）与问题规模 n 之间的关系。空间复杂度 = 递归调用的深度


![[Pasted image 20251005104824.png]]


## 2.2 线性表，广义表

## 2.3 树和二叉树、图
### 2.3.1 树和二叉树

二叉树的遍历：
前序遍历：根左右
中序遍历：左根右
后序遍历：左右根
层次遍历：按层遍历二叉树


树和二叉树的转换，对于每个节点从上到下、从左到右遵循以下规则进行转换：
其左孩子节点 --> 自己的左子树节点
其右兄弟节点 --> 自己的右子树节点


二叉排序树的特点：
对于每个节点的值，其左孩子的值小于根，右孩子的值大于根

构造霍夫曼树（最优二叉树）：
在给定节点序列中不断选取值最小的两个节点构成一颗二叉树

线索二叉树：
节点中不仅存储了节点的值，还存储了节点的前序或者后序的指向信息
因为非叶子节点中的每个节点都额外存储了左右孩子的信息，所以线索二叉树中的线索是存储在叶子节点中的，即叶子节点中的左右孩子指针存储了线索信息。

平衡二叉树：
任意节点的左右子树深度之差的绝对值不超过 1

### 2.3.2 图
有向图：节点之间的边有方向

无向图：节点之间的边没有方向

完全图：
在无向图中，如果每对顶点之间都有一条边相连，则此图为完全图
在有向图中，如果每对顶点之间都有两条有向边相互连接，则此图为完全图

度，入度与出度：
度用于表示无向图的每个节点有几条连线与别的节点相连
入度和出度则用于表示有向图的每个节点，从其出发和指向自己的边分别是多少

图的存储结构：
1）邻接矩阵
用一个 n 阶方阵 R 来存放图中各节点的关联信息，其矩阵元素$R_{ij}$定义为:
$$R_{ij} = \begin{Bmatrix}
			1 & 若顶点 i 到顶点 j 有邻接边 \\
			2 & 若顶点 i 到顶点 j 无邻接边
		   \end{Bmatrix}$$

 2）邻接表
 用一个一维数组顺序存储每个节点，每个数组元素上都挂一个链表，表示此节点的所有邻接节点。（类似于 hash 挂链）

图的遍历：
1）深度优先：
任意选择一个顶点作为遍历的起始节点，选择一个与该节点相连且未被访问过的节点作为下一个访问节点，下一个节点也采取类似操作。如果某个节点所有的相邻节点都被访问过，则回退到上一个节点，并从上一个节点的所有相邻节点中选一个未被访问过的节点继续遍历。

2）广度优先：
任意选择一个节点作为起始节点，依次访问与其相连的所有邻接节点，并依次对这些邻接节点做同样的操作。

图的拓扑排序：
拓扑排序是一个有向无环图的所有顶点的线性序列，且该序列满足两个条件：
1）每个顶点出现且只出现一次。
2）若存在一条从顶点 A 到顶点 B 的路径，那么在序列中顶点 A 出现在顶点 B 的前面。


最小生成树：

给定一张无向联通图，如果它的子图中任意两个顶点都是互相连通，并且是一个树结构，那么这棵树叫做生成树。当连接顶点之间的图有权重时，权重之和最小的树结构为最小生成树！

1）prim 算法：
Prim 算法是一种“加点式”贪心算法，用于在连通无向加权图中求得最小生成树（MST）。它从某一顶点开始，逐步扩展一棵树，每次把“离树最近”的顶点及其对应边拉进来（**树中的所有顶点都被包含在集合中，离树最近的距离就是集合外的顶点离集合中某个顶点的最近距离**），直到所有顶点都包含在这棵树中。

2）Kruskal算法：
Kruskal 算法是一种“加边式”贪心算法，其核心思路是”先把边按权值从小到大排好，然后一条一条加“。需要注意的是在加边的过程中需要保证联通分量不会形成环。

kruskal 算法需要使用并查集来统计所有已经加入边的邻接顶点。

### 2.3.3 查找、排序
#### 2.3.3.1查找

1）顺序查找：
从前向后顺序查找元素所在位置，一般多用于无序数组中的元素查找，时间复杂度 O(n)。

2）二分查找：
在有序的顺序表中查找元素所在位置，时间复杂度$O(log_n)$

3）分块查找：
块间有序，块内无序。
第一步在索引表中确定待查找记录所在块，第二步在块内顺序查找

4）哈西表（散列表）：
数据元素的关键字与其存储地址直接关联（通过 hash 函数计算数据元素的关键字并得到哈希值，哈希值直接对应数据元素的存储位置）

如果不同元素的关键字通过 hash 函数计算后得到同一个 hash 值，则称它们为同义词，同义词会产生了 hash 冲突。

hash 冲突的解决方法：
开放地址法、链地址法、再建 hash 法、


#### 2.3.3.2 排序

重新排列表中的元素并使表中元素按照关键字有序

1.排序性质

按照性质可以将排序分为稳定排序和不稳定排序。稳定性是指排完序后，相同值的元素保证相对位置不变。

稳定排序：冒泡、插入、归并、计数、桶、基数

不稳定排序：选择、希尔、快速、堆


2.排序位置

按照排序所在位置，可以分为内部排序和外部排序。内部排序就是排序过程在内存中完成，外部排序则是排序过程中用到了外存


3.排序方法

插入：直接插入、希尔排序

交换：冒泡、快速

选择：简单选择排序，堆排序

归并：基数排序

4.算法思想

1）直接插入排序：
每次将一个待排序的记录按照其关键字大小插入到前面已经排好序的序列中，直到全部记录插入完成为止。

 2）希尔排序
 希尔排序是直接插入排序的优化，先把整个序列切成若干子序列（**相隔 gap 的元素为一组**），对每组做直接插入排序；再不断缩小 gap 直到 1，最终变成一次普通插排，此时数据已基本有序，移动次数极少。

![[Pasted image 20251007152607.png]]


希尔排序的 gap 一般从数组长度的一半开始，每执行完依次排序后 gap = gap / 2，一直到 1 并进行最后一次排序。


希尔排序最开始的时候只需要对少量元素进行比较和交换，在gap 逐步减小的过程中每个序列中需要比较的元素逐步增多，但此时整体序列中的有序性也在逐步增大，所以交换的次数也不会上升的很快。

3）冒泡排序：
从后向前（或者从前向后）两两比较相邻元素的值，如果为逆序（A[i - 1] > A[i]）则交换它们，直到一次比较完成则为一次冒泡完成。 

4）快速排序：
采用分治的思想，在一组数据中选择任意一个数据（通常是第一个或者最后一个）作为比较的基准，将大于其值的元素全部移到一边，小于其值的元素移动到另一边。之后再用同样的方法处理两边的元素，直到最后序列中的所有元素都有序为止。

快速排序不稳定是因为**排序时基准值的选择**问题。比如以下序列：

2 4 5 1 2 6 8 7 4 3 1 

此时以第一个值 2 作为第一次排序的基准值，此时从 2 后面开始遍历，找比 2 大的值，同时从最后一个位置开始向前查找比 2 小的值。发现顺序查找时4 比 2 大，同时逆序查找时1 比 2 小，将两者交换，那么此时原本第一个 4 就变到了第二个四的后面，此时相同值的相对顺序就被破坏了。


5）简单选择排序：
每一次都在待排序的元素中选择一个关键字最大（或者最小）的值加入有序子序列中

6）堆排序：
堆是一种完全二叉树的数据结构，可以分为大根堆和小根堆。大根堆中每个节点的值都大于其左右孩子节点的值，小根堆中每个节点的值都小于其左右孩子节点的值。

![[Pasted image 20251007164244.png]]

![[Pasted image 20251007164255.png]]


以大根堆举例，排序步骤如下：

首先将待排序的元素序列建立堆，然后从堆底开始，从下向上比较当前节点和父节点的值。如果当前节点的值大于父亲节点，就将当前节点的值与父节点的值进行交换，始终保持父节点的值大于孩子节点。经过多次比较交换后，最终建立了一个大顶堆。

之后从此大顶堆开始，将堆顶值与最下方的孩子节点值进行交换，并将交换后的孩子节点从堆中移除，也就是此时堆中的最大值已被移除，并作为降序排序的第一个元素。因为交换后的堆不再满足大顶堆的性质，所以从底部节点开始重新执行一次比较和交换操作（因为交换后只有堆顶的元素不满足大顶堆性质，堆中其他节点都满足，所以此时仅需要从堆顶开始重新比较一遍即可）


**总结：先建堆，再删顶。大顶堆获取降序序列，小顶堆获取升序序列。**

7）归并排序
归并排序的核心思想是**先分后并**。先把数组递归二分到只剩 1 个元素（天然有序），再两两合并成有序段，直到最终合并成一个完整的有序序列。

![[Pasted image 20251007174516.png]]

核心操作：
双指针扫描两有序段，每次取较小者放入临时数组，最后拷回原位。

特点：
时间 O(n log n)（始终二分）

空间 O(n)（需临时缓冲区）

稳定（相等元素左段先出，保持原序）

8）基数排序
原理：
将整数按位数切割成不同的数字，逐位进行分配和收集（从最低位开始，将每个元素按照对应位分配到对应的桶中，全部分配完后再从桶中从前向后重新收集起来）

基数排序的方式可以采用LSD（Least significant digital）或MSD（Most significant digital），LSD的排序方式由键值的最右边开始，而MSD则相反，由键值的最左边开始。

- **MSD**：先从高位开始进行排序，在每个关键字上，可采用计数排序
- **LSD**：先从低位开始进行排序，在每个关键字上，可采用桶排序

实现逻辑（LSD）：
- 将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。  
- 从最低位开始，依次将对应位的值按照顺序分配到桶中，然后再从桶中收集。
- 每个桶都是先进先出队列，这样保证每一位值排序并插入桶中，再从桶中取出时顺序不变。
- 这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。




9）排序的评价指标：
![[Pasted image 20251007233614.png]]


![[Pasted image 20251007213212.png]]


# 三.算法设计与分析

## 3.1 分治

1.核心思想：
将复杂问题分解为多个规模较小、结构相似的子问题，**递归求解后再合并结果。**

原问题的最优解一定由子问题的最优解组合而成

2.算法步骤：

1）分解（Divide）​​

将原问题拆分为 ​**k 个规模更小且相互独立**​ 的子问题，子问题与原问题性质相同。

例如，将数组分为两半，或将棋盘切割为子棋盘

2）解决（Conquer）​​
- **递归求解**​：若子问题规模足够小（如单元素数组），直接求解；否则继续分解。
- **基线条件**​：当子问题不可再分时，直接返回结果（如数组最大值问题中，单个元素即为最大值）

 3）合并（Combine）​​

将子问题的解合并为原问题的解。

例如，归并排序中将两个有序子数组合并为有序数组，或棋盘覆盖中通过L型方块合并子棋盘的解

3.适用条件

分治法需满足以下条件：

1）**可分解性**​：问题能拆分为结构相同的子问题（如排序、查找）。
    
2）​**独立性**​：子问题互不依赖，避免重复计算（动态规划更适合重叠子问题）。
    
3）**可合并性**​：子问题的解能有效合并为原问题的解（如最大值比较、数组合并）

4.优缺点分析

**优点**​： 
1）降低复杂度​：通过分解问题减少计算量（如快速排序的时间复杂度为 O(nlogn)）。   
2）并行优化​：<font color=red>子问题可并行处理，提升效率</font>（如多核环境下的任务分配）

**缺点**​：    
1）递归开销：递归调用可能带来栈空间消耗和额外计算（如函数调用、参数传递） 
2）合并成本​：若合并步骤复杂，可能抵消分解带来的收益（如矩阵乘法的分治合并）


## 3.2 回溯
回溯算法（Backtracking Algorithm）是一种通过**试错搜索**和**路径回退**来寻找问题解的通用策略，尤其适用于组合优化、约束满足等问题。其核心思想是**深度优先搜索（DFS）​**结合**剪枝优化**，通过逐步构建解并在发现无效时回溯到上一步，尝试其他可能性

1.核心思想与关键要素
1）​解空间树遍历​

回溯算法将问题的所有可能解组织成解空间树，通过深度优先的方式遍历树的节点。例如：

​子集树​：用于组合问题（如子集、组合总和），每个节点表示是否选择某个元素

​排列树​：用于排列问题（如全排列、字符串排列），每个节点表示元素的排列顺序


2）​递归与回溯​

​选择路径​：从当前节点选择一个分支继续探索

​验证条件​：检查当前路径是否满足约束（如无重复元素、符合规则）

​递归搜索​：若有效，递归进入下一层；若无效，回溯到上一步并尝试其他分支

​3）剪枝优化​

​约束函数​：提前终止不满足条件的分支（如数独中行/列重复）

​界函数​：跳过不可能产生更优解的分支（如背包问题中当前价值已超最优解）



## 3.3 贪心
贪心算法（Greedy Algorithm）是一种通过每一步选择当前最优解来逐步逼近全局最优解的算法设计策略。其核心思想是**​“局部最优驱动全局最优”​**，适用于具有特定性质的问题

1.核心思想
1）​贪心选择性质​

在每一步决策中，仅基于当前状态选择局部最优解，且该选择能保证最终全局最优。例如，在找零问题中，优先选择面值最大的硬币以减少总张数

​2）最优子结构​

问题的全局最优解包含其子问题的最优解。例如，在最小生成树问题中，整体最优的边集合由局部最优的边逐步扩展而来

​3）无后效性​

当前选择仅影响后续步骤，而不会因后续决策改变已做出的选择。例如，活动选择问题中，一旦选择结束时间最早的活动，后续选择不再考虑该活动。

3.贪心算法的实现步骤

​1）问题建模​
将问题抽象为数学模型，明确目标函数和约束条件。例如，背包问题中目标为最大化价值，约束为总重量不超过容量。

2）​分解子问题​

将原问题分解为多个局部决策步骤。例如，在哈夫曼编码中，每次合并频率最小的两个节点。

​3）局部最优选择​

定义贪心策略（如最大收益、最小成本），并执行选择。例如，Dijkstra算法中每一步选择距离起点最近的节点。

​4）合成全局解​

将局部解合并为全局解。例如，Kruskal算法通过逐步选择最小边构建最小生成树。

4.贪心算法的适用条件

1）​问题需满足贪心选择性质​

局部最优解能推导出全局最优解。例如，分数背包问题中按单位重量价值排序可得到最优解。

​2）问题具有最优子结构​

子问题的最优解可组合为原问题的最优解。例如，最短路径问题中，两点间的最短路径包含中间点的最短路径。

​3）无后效性​

当前决策不影响后续选择的可能性。例如，任务调度中按处理时间排序后，后续任务无需重新评估之前的选择。

5.优缺点
​1）优点​
实现简单，时间复杂度低（通常为 O(nlogn)）

无法保证全局最优解（如0-1背包问题）

适用于大规模数据（如最小生成树、最短路径）

​2）缺点​

对问题性质要求严格（需满足贪心选择和最优子结构）

无需回溯，空间复杂度低

部分问题需特殊处理（如哈夫曼编码需优先队列）

6.典型应用场景
​1）经典问题​

​活动选择​：按结束时间排序，选择最多不重叠活动。

​最小生成树​：Prim/Kruskal算法通过局部边选择构建全局最优树。

​哈夫曼编码​：合并频率最低的节点生成最优前缀编码。

​2）实际应用​

​任务调度​：按处理时间分配资源以减少等待。

​图像压缩​：基于像素相似性合并区域（如JPEG编码）。

​网络路由​：Dijkstra算法寻找单源最短路径。



## 3.4 动态规划

1.概述：

动态规划（Dynamic Programming, DP）是一种通过将复杂问题分解为相互关联的子问题，并存储子问题的解以避免重复计算的算法设计策略。其核心思想是**​“最优子结构”​**和**​“重叠子问题”​**的结合，适用于需要全局最优解的优化问题。

最优子结构意味着问题的最优解包含子问题的最优解，而重叠子问题则指子问题会被多次计算，动态规划通过存储这些子问题的解来避免重复计算，提高效率。

2.核心思想：
1）最优子结构（Optimal Substructure）​​

问题的最优解包含其子问题的最优解。例如，最短路径问题中，从A到C的最短路径经过B，则A到B的最短路径必然也包含在从A到C的最短路径中。

​2）重叠子问题（Overlapping Subproblems）​​

子问题在求解过程中会被多次重复计算。例如，斐波那契数列的递归计算会重复计算fib(n-1)和fib(n-2)，而动态规划通过存储已计算结果避免冗余。


​3）状态定义与转移方程​

​状态（State）​​：描述子问题的关键变量。例如，背包问题中$dp[i][j]$表示前i个物品在容量j下的最大价值。

​状态转移方程​：定义子问题如何组合为更大问题的解。

3.动态规划的实现步骤

1）​划分阶段​：

将问题按时间或空间特征分解为有序的子问题。例如，斐波那契数列按递推顺序划分为fib(n-1)和fib(n-2)两个阶段。

2）​确定状态与状态变量​

选择能描述子问题的变量。例如，最长公共子序列（LCS）问题中，状态定义为$dp[i][j]$表示序列$X[1..i]$和$Y[1..j]$的LCS长度。

3）​设计状态转移方程​

根据子问题间的逻辑关系推导递推式。例如，编辑距离问题中，状态转移方程需考虑插入、删除、替换三种操作的最小代价。

​4）初始化边界条件​

确定最小子问题的解。例如，斐波那契数列的初始条件为fib(0)=0和fib(1)=1。

5）​填表计算与回溯​

​自底向上​：通过迭代填充DP表（如二维数组），逐步求解更大子问题。
例如，背包问题按物品和容量顺序填充表格。

​自顶向下​：递归求解并缓存中间结果（记忆化搜索），适合子问题数量较少的情况

4.动态规划的分类与典型应用

| ​**分类**​   | ​**特点**​              | ​**典型问题**​         |
| ---------- | --------------------- | ------------------ |
| ​**线性DP**​ | 子问题按线性顺序依赖（如数组、字符串）   | 斐波那契数列、最长递增子序列     |
| ​**区间DP**​ | 子问题依赖区间内的多个状态（如矩阵链乘法） | 石子合并、多边形三角剖分       |
| ​**背包问题**​ | 资源分配优化，需满足容量约束        | 0-1背包、完全背包、多重背包    |
| ​**图论DP**​ | 结合图结构的状态转移（如最短路径、网络流） | Dijkstra算法变种、旅行商问题 |


# 四.操作系统基本原理

## 4.1 基本概念

1.定义
操作系统（Operating System, OS）是管理计算机硬件与软件资源的系统软件，直接运行在裸机上，是用户与计算机硬件之间的接口，也是其他软件运行的基础平台。其核心作用包括：

​1）资源管理​：协调CPU、内存、存储设备、输入输出设备等硬件资源，以及文件、进程等软件资源。

​2）服务提供​：为用户和应用程序提供便捷的操作界面（如命令行或图形界面）及系统调用接口。

​3）抽象与封装​：隐藏硬件复杂性，通过虚拟化技术（如虚拟内存）简化资源使用。

2.核心功能

操作系统的主要功能模块包括：

1）​进程管理​

负责进程的创建、调度、终止及通信，支持多任务并发执行（如时间片轮转、优先级调度）。

通过进程控制块（PCB）记录进程状态，实现进程间同步与互斥


2）​内存管理​

分配与回收内存空间，实现虚拟内存技术以扩展物理内存容量


采用分页、分段等技术管理内存地址空间，防止进程间干扰


3）​文件系统管理​

组织和管理磁盘文件，支持目录结构、文件权限控制及日志式存储（如NTFS、ext4）

提供文件读写、存储空间分配等接口


4）​设备管理​

通过驱动程序控制外设（如打印机、键盘），实现高效I/O操作。

采用缓冲技术减少设备访问延迟。

​5）用户界面​

提供图形用户界面（GUI）或命令行界面（CLI），降低用户操作门槛。

3.基本特性

1）​并发性​

多个程序或任务在同一时间段内交替执行，宏观上表现为并行。

单核CPU通过时间片轮转实现并发
多核CPU可并行执行同cpu核数相同的任务

​2）共享性​

资源被多个进程共享，分为互斥共享（如打印机）和同时共享（如内存）。

​3）虚拟性​

通过虚拟化技术将物理资源抽象为逻辑资源（如虚拟内存、虚拟机）。

​4）异步性​

进程执行顺序不确定，受资源分配和调度策略影响。




## 4.2 进程管理

### 4.2.1.状态转移
进程在五种状态之间进行转移

1）新建态
- 条件​：进程刚被创建，系统分配PCB和资源。
    
- ​转换路径：新建 → 就绪​：资源分配完成，加入就绪队列。

2）就绪态
- 条件​：进程已分配除CPU外的所有资源，等待调度器分配CPU。
​
- 转换路径​：
    ​就绪 → 运行​：调度器选中该进程（如时间片轮转或优先级调度）。
    
    ​运行 → 就绪​：时间片耗尽或被高优先级进程抢占。


3）运行态
- ​条件​：进程正在CPU上执行。
    
- ​转换路径​：
    运行 → 阻塞​：进程请求I/O、信号量等资源未满足。
        
    ​运行 → 终止​：进程完成任务或异常退出。

4）阻塞态
- 条件​：进程因等待外部事件（如I/O完成）而暂停执行。

- 转换路径​：
    ​阻塞 → 就绪​：等待的事件完成（如I/O操作结束）。

5）终止态
- 条件​：进程执行完毕或被强制终止。

- ​转换路径​：
    ​运行 → 终止​：正常退出或异常终止。

    ​阻塞 → 终止​：系统强制终止阻塞中的进程（如资源回收）。


**关键点：**

1）**不能由阻塞态直接转移为运行态，也不能由就绪态直接转移为阻塞态。** 因为运行态 -> 阻塞态是一种进程自身做出的主动行为。

2）阻塞态 -> 就绪态 不是进程自身控制的，是一种被动行为。因为阻塞态的进程只能等待外部事件的发生，才会被通知获取到资源并转移为就绪态

3）时间片耗尽或抢占仅导致运行态转就绪态，而非阻塞态


**状态转换表**​：

| 当前状态 | 转换条件     | 目标状态 |
| ---- | -------- | ---- |
| 新建态  | 资源分配完成   | 就绪态  |
| 就绪态  | 调度器选中    | 运行态  |
| 运行态  | 时间片耗尽/抢占 | 就绪态  |
| 运行态  | 等待I/O或资源 | 阻塞态  |
| 阻塞态  | 等待事件完成   | 就绪态  |
| 运行态  | 执行完毕/异常  | 终止态  |

### 4.2.2.进程的前驱图
进程的前驱图（Precedence Graph）是操作系统中用于描述进程或任务间执行顺序依赖关系的核心工具，其本质是一个**有向无环图（DAG）**，通过有向无环结构确保任务按正确顺序执行，避免死锁和资源竞争。结合信号量机制和 PV 操作，前驱图能够高效实现进程同步，广泛应用于进程调度、资源管理和分布式系统中。理解前驱图的结构与实现原理，对设计高并发、高可靠性的系统至关重要。


### 4.2.3.进程的同步机制
进程的同步机制是操作系统协调并发进程执行顺序、避免资源竞争和数据不一致的核心手段。其核心目标是通过规则和工具确保进程在共享资源访问、协作执行时满足**互斥性**和**时序性。**

1.同步机制分类与原理
1）软件同步机制

Peterson算法：

通过共享变量（`wanted_in`和`observer`）实现两个进程的互斥访问。每个进程进入临界区前需设置标志位并检查对方状态，确保仅一个进程进入临界区。
    
优点​：避免忙等待，满足四项准则。
    
缺点​：仅适用于两个进程，扩展性差

    
Dekker算法：​

通过轮询和交换意图标志实现互斥，但实现复杂且效率较低。

2）硬件同步机制

- 关中断法​：

进程进入临界区后关闭中断，退出后重新开启。

​优点​：简单高效。

​缺点​：仅适用于单CPU系统，滥用可能导致系统崩溃


- Test-and-Set（TSL）指令​：

原子性完成“读取-修改-写入”操作，例如：
```
while(TSL(lock));  // 自旋等待锁释放
lock = 0;          // 释放锁
```

- swap 指令：
原子交换两个变量的值，实现与TSL类似的效果。


3）信号量机制
- 整型信号量

通过P（wait）和V（signal）操作管理资源计数。

​**问题**​：忙等待（`while(S<=0)`），违背“让权等待”准则

- 记录型信号量

引入等待队列，进程无法获取资源时进入阻塞态并放入等待队列中

​**优点**​：避免忙等待，符合四项准则。

结构：
```
typedef struct { int value; PCB *L; } semaphore;
```

- AND型信号量

一次性分配多个资源，避免死锁

操作：
```
Swait(S1, S2);  // 同时申请S1和S2
Ssignal(S1, S2); // 同时释放
```

适用场景：
哲学家进餐问题中同时获取左右筷子


- 信号量集

扩展AND型信号量，支持资源下限检查（如`Swait(S, t, d)`）。

4）管程机制
核心思想：
把共享数据和对共享数据的操作封装在一起，提供一个线程安全的访问机制，避免竞争条件和死锁

特点：
- 互斥性：同一时间仅一个进程进入管程。

- 条件变量：`wait()`阻塞进程，`signal()`唤醒等待进程

示例：
读者写者问题中，通过管程管理读写优先级。

```
// 多个读者可同时读
// 写者独占
// 写者优先（一旦写者等待，新读者不能插队）

monitor RWController {
    int  nr = 0;          /* 正在读的读者数   */
    bool busy = false;    /* 是否有写者在写 */
    condition OKread;     /* 等待读的队列     */
    condition OKwrite;    /* 等待写的队列     */

    procedure entry startRead() {
        /* 有写者正在写，或写者已排队 → 读者等待 */
        while (busy or not empty(OKwrite))   
            wait(OKread);
            
        nr = nr + 1;
        signal(OKread);   /* 唤醒后续排队读者 */
    }

    procedure entry endRead() {
        nr = nr - 1;
        if (nr == 0)      /* 最后一个读者唤醒写者 */
            signal(OKwrite);
    }

    procedure entry startWrite() {
        while (busy or nr > 0)   /* 有写者或读者在 → 写者等待 */
            wait(OKwrite);
        busy = true;
    }

    procedure entry endWrite() {
        busy = false;
        if (not empty(OKwrite))   /* 优先唤醒写者 */
            signal(OKwrite);
        else
            signal_all(OKread);   /* 否则一次性放行所有读者 */
    }
}


// 使用模板
reader:
    loop {
        RWController.startRead();
        /* 临界区：读操作 */
        RWController.endRead();
    }

writer:
    loop {
        RWController.startWrite();
        /* 临界区：写操作 */
        RWController.endWrite();
    }


```

2.经典同步问题与解决方案
1）生产者消费者问题
同步要求：
缓冲区满时阻塞生产者，缓冲区空时阻塞消费者

互斥访问缓冲区

实现：使用记录型信号量
```
semaphore mutex = 1;  // 互斥信号量
semaphore empty = N;  // 空缓冲区计数
semaphore full = 0;   // 满缓冲区计数
```

2）哲学家进餐问题

解决方案：
使用and型信号量
资源分级，奇数拿左边，偶数拿右边


3）读者写者问题
读者写者互斥，写者和写者互斥，读者和读者不互斥

可以分为读者优先和写者优先两种算法


3.同步机制设计准则（四项准则）
为了实现对临界资源的互斥访问，同时保证系的整体性能，进程之间需要保证以下四条规则：

- **空闲让进**​：临界资源空闲时允许其他进程访问临界资源。

- ​**忙则等待**​：当临界资源被占用时，其他需要获取临界资源的进程会阻塞。

- ​**有限等待**​：进程因为等待临界资源而阻塞时，应该保证被阻塞进程能在有限时间内获取到临界资源，防止被饿死。

- ​**让权等待**​：被阻塞的进程立即释放CPU，避免空等并消耗cpu资源


4.同步机制间的优缺点对比

| 机制   | 优点           | 缺点          |
| ---- | ------------ | ----------- |
| 锁    | 简单易用         | 易死锁         |
| 信号量  | 支持复杂同步，灵活性高  | 需要正确配对PV操作  |
| 管程   | 代码结构化，避免竞态条件 | 实现复杂，语言依赖性强 |
| 硬件机制 | 原子性强，高效      | 忙等待，适用场景有限  |


5.实际应用场景
1）操作系统内核​：进程调度、内存管理需严格同步。

​2）数据库事务​：通过锁机制保证ACID特性。

​3）分布式系统​：Raft算法通过日志同步实现一致性。

​4）并行计算​：OpenMP通过屏障（Barrier）同步线程。


### 4.2.4 死锁
1.必要条件
死锁必须同时满足以下四个条件，任意一个条件不满足都不会产生死锁

- 互斥：只有对必须互斥使用的资源的争抢才会导致死锁。

- 不可剥夺：进程所获得的资源在未使用完之前，不能由其他进程强行夺走。

- 请求和保持：进程已经保持了一个资源的同时，又提出对新资源的请求，此请求的资源被其他进程保持。同时每个进程对保持的资源不释放。

- 循环等待：存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被下一个进程请求。

2.处理策略

1）死锁预防：破坏死锁产生的必要条件中的一个或几个，从根本上杜绝死锁的发生


特点：静态策略，无需运行时检查，但可能导致资源利用率较低

缺点：过度限制资源分配，导致系统吞吐率下降

2）死锁避免：运行时动态检查资源分配状态，确保系统始终处于安全状态（至少存在一个安全序列，所有进程可以顺利完成）

特点：需要预先知道进程的最大资源需求（最大需求矩阵），通过算法判断是否允许分配

关键算法：银行家算法
- 数据结构：
    - Max ：进程对各类资源的最大需求
    - Allocation：已分配给进程的资源
    - Need：Max - Allocation，进程可能还需要的资源数
    - Available：系统当前可用资源

- 安全状态判断：
    1）寻找Need[i] <= Available 的进程p_i
    2）假设进程p_i 获得运行资源并运行完成，释放其占用的所有资源， Available += Allocation[i]
    3）重复上述过程，如果存在一个序列能让所有进程执行完成，此序列为安全序列

- 资源分配流程：当进程请求资源时，**仅当分配后系统仍处于安全状态才可以分配**，否则阻塞进程。

缺点：
- 需预先知道进程的最大资源需求（实际中难以准确预测）。
- 算法复杂度为O(m×n²)（m资源类，n进程数），频繁调用可能带来开销。
- 资源利用率仍低于无死锁控制的系统（因保守分配）。

3）死锁检测和死锁预防对比

| 维度    | 死锁预防            | 死锁避免                   |
| ----- | --------------- | ---------------------- |
| 触发时机  | 编译时/资源分配前（静态）   | 运行时动态检查（每次资源请求时）       |
| 信息需求  | 无需预知进程后续资源请求    | 需预知最大资源请求（MAX矩阵）       |
| 资源利用率 | 最低（强制破坏必要条件）    | 中等（仅拒绝不安全分配）           |
| 实现复杂度 | 简单（一次性分配或资源编号）  | 复杂（需要维护矩阵并计算安全序列）      |
| 典型算法  | 静态资源分配，资源有序分配法  | 银行家算法                  |
| 适用场景  | 资源需求明确且固定的嵌入式系统 | 资源需求可预测的分时系统（早期皮批处理系统） |
|       |                 |                        |



4）死锁的检测和解除：允许死锁的发生，不过发现死锁发生后会采用某种方法解除死锁

现代操作系统一般采用 死锁检测 + 恢复 算法（定期检测死锁并终止或回滚进程），主要包含以下原因：
- 预防和避免的开销过高，且难以预测进程的资源需求
- 死锁发生的概率较低，检测+恢复方法系统吞吐量更高


## 4.3 存储管理
### 4.3.1 内存空间的分配与回收

#### 4.3.1.1 连续分配管理方式
在连续分配内存的时代，内存还没有采用分页/分段方式，进程需要的内存会被整段申请。当进程执行结束后，内存中会存在一段一段的不连续内存区域。

1.单一连续分配
最简单的内存管理方式，只能用于单任务单用户的操作系统中。

把内存分为系统区和用户区两部分，系统区仅提供给OS使用，通常是放在内存的低址部分
。用户区是指除系统区以外的全部内存空间，提供给用户使用。


2.固定分区分配

特点：

- **预先划分内存**：内存被**静态划分**为若干个大小固定的分区（可能相同或不同），分区大小在系统启动时确定，之后无法改变。
- **分区数量固定**：分区数量和大小由操作系统预先定义，例如分为小、中、大三种分区。
- **每个分区只能装入一个进程**：如果进程大小超过分区大小，则无法运行；如果进程小于分区，会导致**内部碎片**（分区内未使用的内存浪费）。

优点：

- 实现简单，管理开销低。
- 适用于已知任务规模的场景（如批处理系统）。

缺点：

- **内部碎片**：分区未被进程占用的部分无法被其他进程利用。
- **灵活性差**：无法适应动态变化的进程内存需求。

示例：

- 将内存划分为：64KB、128KB、256KB三个分区。一个50KB的进程只能放入64KB分区，剩余14KB被浪费。


3.动态分区分配
1）首次适应算法
首次适应算法从内存的**低地址端**开始顺序扫描空闲分区链表，找到第一个满足请求大小的空闲分区进行分配。若找到，则分配该分区（可能分割剩余空间）；若未找到，则分配失败

**实现特点**​

- ​**数据结构**​：空闲分区链表按地址递增顺序排列。
    
- ​**分配过程**​：线性扫描链表，直到找到合适分区。
    
- ​**剩余空间处理**​：若分区剩余空间大于0，则生成新的空闲分区插入链表尾部。
    

​**优缺点**​

- ​**优点**​：实现简单、分配速度快，保留了高地址的大块空闲区。
    
- ​**缺点**​：低地址区易产生外部碎片，频繁的小请求可能导致高地址大块被分割

​**应用场景**​

适用于对响应速度要求高、内存碎片不敏感的系统（如早期UNIX系统）

2）最佳适应算法
最佳适应算法遍历整个空闲分区链表，选择**最小的足够大**的空闲分区进行分配。其目标是尽量减少内存浪费

**实现特点**​

- ​**数据结构**​：空闲分区链表按容量递增排序。
    
- ​**分配过程**​：需遍历所有分区，找到最小合适分区。
    
- ​**剩余空间处理**​：分割后剩余空间可能非常小，需保留为独立空闲分区。
    

​**优缺点**​

- ​**优点**​：减少内部碎片，提高内存利用率。
    
- ​**缺点**​：查找耗时（需遍历全表），易产生大量微小碎片，后续大请求可能无法满足
    

​**应用场景**​

适用于内存碎片敏感、需高效利用小块内存的场景（如嵌入式系统）

3）最差适应
最坏适应算法选择**最大的空闲分区**进行分配，目的是保留较小的空闲区供后续小请求使用

**实现特点**​

- ​**数据结构**​：空闲分区链表按容量递减排序。
    
- ​**分配过程**​：直接分配最大可用分区，分割后剩余空间可能较大。
    
- ​**剩余空间处理**​：若剩余空间仍足够大，则保留为独立分区。
    

​**优缺点**​

- ​**优点**​：避免产生过小碎片，保留大块空间。
    
- ​**缺点**​：快速耗尽大块内存，导致后续大请求失败；可能增加内部碎片
    

​**应用场景**​

适用于大进程频繁、小请求较少的系统（如批处理任务）

4）邻近适应
邻近适应算法是首次适应的改进版，分配时从**上次分配结束的位置**开始扫描，而非每次从头开始。若遍历到链表末尾，则循环回头部继续查找

**实现特点**​

- ​**数据结构**​：空闲分区链表按地址递增顺序排列。
    
- ​**分配过程**​：维护一个指针记录上次分配位置，从该位置开始查找。
    
- ​**剩余空间处理**​：与首次适应相同。
    

​**优缺点**​

- ​**优点**​：减少低地址区频繁扫描，平衡内存使用。
    
- ​**缺点**​：高地址区大块可能被过早分割，长期运行后碎片问题仍存在

​**应用场景**​

适用于中等规模内存、需平衡分配效率与碎片控制的系统


#### 4.3.1.2 非连续分配管理方式
在操作系统的非连续分配内存管理方式中，程序的内存空间被划分为多个不连续的物理块，通过逻辑地址与物理地址的映射机制实现灵活分配。

1.分页存储管理方式

分页存储管理方式中，根据运行作业时是否把作业所有页面装入到内存中才能运行分为基本分页存储管理和请求分页存储管理。

1）核心概念​

- ​**划分方式**​：将内存和进程的逻辑地址空间均划分为**固定大小**的页（如4KB），物理内存的块称为页框（Frame）。
    
- ​**映射机制**​：通过**页表**记录逻辑页号到物理页框号的映射关系，实现离散分配。
    

2）地址转换流程​

- ​**逻辑地址结构**​：由页号（高位）和页内偏移量（低位）组成。
    
- ​**转换步骤**​：
    
    1. ​**拆分地址**​：页号 = 逻辑地址 ÷ 页大小；页内偏移量 = 逻辑地址 % 页大小。
        
    2. ​**查页表**​：根据页号获取对应的物理页框号。
        
    3. ​**计算物理地址**​：物理地址 = 物理页框号 × 页大小 + 页内偏移量。
        
    

3）优化技术​

- ​**快表（TLB）​**​：缓存高频访问的页表项，减少内存访问次数（从2次降至1次）
- ​**多级页表**​：将页表分层次存储（如两级页表），解决单级页表占用连续内存的问题


4）优缺点​
- ​**优点**​：消除外部碎片，内存利用率高。
- ​**缺点**​：存在页内碎片；页表可能占用大量内存（如32位系统需4MB页表）。

5）应用场景​

- 通用操作系统（如Linux、Windows）的基础内存管理。


2.分段存储管理方式

1）核心概念​

- ​**划分方式**​：按程序逻辑模块（如代码段、数据段、堆栈段）划分内存，段的大小可变。
    
- ​**映射机制**​：通过**段表**记录每个段的基地址和长度，支持动态增长。
    

2）​地址转换流程​

- ​**逻辑地址结构**​：由段号和段内偏移量组成。
    
- ​**转换步骤**​：
    
    1. ​**查段表**​：根据段号获取段的基地址和长度。
        
    2. ​**合法性检查**​：段内偏移量是否超过段长度。
        
    3. ​**计算物理地址**​：基地址 + 偏移量。
        
    

3） ​优化技术​

- ​**共享段**​：多个进程共享同一逻辑段（如共享库），减少内存占用。
    
- ​**保护机制**​：为每个段设置访问权限（读、写、执行）。
    

4）优缺点​

- ​**优点**​：符合程序逻辑结构，支持动态扩展和共享。
    
- ​**缺点**​：易产生外部碎片；地址转换开销较大。
    

5）应用场景​

- 需要模块化管理的系统（如多任务操作系统）。


3.段页式管理方式
1）核心概念​

- ​**结合分页与分段**​：先将程序逻辑分段，再对每个段进行分页管理。
    
- ​**映射机制**​：通过**段表**和**页表**两级映射实现地址转换。
    

2）地址转换流程​

- ​**逻辑地址结构**​：由段号、页号和页内偏移量组成。
    
- ​**转换步骤**​：
    
    1. ​**查段表**​：根据段号获取段的基地址和页表起始地址。
        
    2. ​**查页表**​：根据页号获取物理页框号。
        
    3. ​**计算物理地址**​：基地址 + 物理页框号 × 页大小 + 页内偏移量。
        
    

3）优化技术​

- ​**反向页表**​：以物理页框号为索引，减少内存占用（适用于大地址空间系统）
    
- ​**哈希方案**​：通过哈希函数快速定位页表项，提升查询效率。
    
4）优缺点​

- ​**优点**​：兼顾灵活性与内存利用率，支持虚拟内存。
    
- ​**缺点**​：地址转换复杂（需两次查表），内存访问延迟较高。
    

5）​应用场景​

- 大型系统（如数据库服务器）和需要虚拟内存支持的环境。

### 4.3.2 页面置换算法
#### 4.3.2.1 最佳置换（OPT）
**原理**​：选择未来最长时间内不再被访问的页面进行置换。若页面未来很长时间不会被使用，则优先淘汰它

**优缺点**​：

 - ​**优点**​：理论上缺页率最低，可作为其他算法的性能基准

- ​**缺点**​：无法预知未来访问序列，实际中无法实现

**应用**​：仅用于理论分析或算法性能对比

#### 4.3.2.2 先进先出（FIFO）
**原理**​：淘汰最早进入内存的页面。维护一个队列结构，新页面加入队尾，置换时选择队首页面换出。

**优缺点**​：

- ​**优点**​：实现简单，无需额外硬件支持

- ​**缺点**​：可能引发**Belady异常**​（增加物理内存反而导致缺页率上升）；忽略页面使用频率，可能淘汰活跃页面。比如活跃页面最早进入队列中，在缺页发生时候反而被换出。

**应用**​：适用于对性能要求不高的场景，如早期操作系统


#### 4.3.2.3 最近最久未使用（LRU）

**原理**​：淘汰最近一段时间内最久未被访问的页面，基于“局部性原理”假设未来访问模式与过去相似。

**实现方式**​：
- ​**硬件支持**​：需记录页面访问时间，或者使用 栈或链表 维护访问顺序。

- ​**近似实现**​：通过访问位（如LRU-K算法）或计数器模拟

**优缺点**​：
- **优点**​：性能接近OPT，能有效反映程序访问模式

- **缺点**​：硬件成本高（需维护访问时间或计数器）


**应用**​：广泛用于现代操作系统（如Linux的页面缓存管理）
#### 4.3.2.4 时钟算法（CLOCK）
**原理**​：结合FIFO和LRU思想，使用环形链表存放页面，同时链表上的每个页面对应一个访问位。页面进入内存时访问位置1；置换时扫描链表，如果当前页面的访问位为1就将其设置为0并继续访问下一个页面，如果当前页面的访问位为0就将其换出。

 
**优缺点**​：
- ​**优点**​：实现简单，开销低于LRU

- ​**缺点**​：可能淘汰仍需使用的页面，需周期性扫描链表

**应用**​：常见于UNIX系统及嵌入式设备


## 4.4 文件管理

4.4.1 索引分配

4.4.2 空闲存储空间的管理

1）空闲区表（空闲文件目录）
原理：
维护一张空闲表，记录所有空闲区的起始块号和块数。分配时按需查找合适的空闲区，回收时合并相邻空闲区。

实现特点：
- 连续分配​：适用于顺序文件，分配效率与空闲表长度相关。
    
- 合并操作：回收时需检查前后空闲区是否相邻，避免碎片。
    
- 局限性​：空闲表过大时扫描效率低，不适合碎片化严重的场景

应用场景：
早期文件系统（如FAT）或小型存储设备

2）位视图法
原理：
用二进制位表示磁盘块状态（0=空闲，1=已分配）。分配时扫描位示图寻找连续0位，回收时置0。

实现细节：
- 位与块的映射：例如每32位对应一个字，通过`(块号-1)/字长`计算行号，`(块号-1)%字长`计算列号。
- ​高效性：位操作速度快，适合大容量磁盘管理（如Linux系统）
- ​空间开销：需额外存储位示图，但相比链表节省空间

示例：
分配块200时，计算其对应位示图位置为行13、列8，置该位为1。


3）空闲链表法
原理：
所有空闲块通过指针链接成一个链表，每个空闲块指向下一个空闲块

优缺点：
- 优点：分配/回收操作简单，无需复杂数据结构
- 缺点：随机访问效率低，链表过长时维护成本高
- 改进：UNIX系统通过成组链接法优化链表长度


4）成组链接法
原理：
结合链表与分组管理，将空闲块按固定大小分组（如每100块一组），每组首块记录组内块数和下一组地址。

操作流程：
- 分配​：优先从第一组分配，若不足则加载下一组数据到内存。
    
- 回收​：新释放块存入第一组，若组满则创建新组并更新指针。
    
- 尾部标识​：最后一组用特殊值（如0）标记结束


优势：
- 高效性：减少磁盘I/O次数，适合大型文件系统
- 灵活性：兼顾空闲块快速访问与碎片管理

## 4.5 设备管理

## 4.6 微内核操作系统








引用文档：
https://blog.csdn.net/OYMNCHR/article/details/119119136
https://zhuanlan.zhihu.com/p/1952330161077846156
https://mp.weixin.qq.com/s?__biz=MzI0ODU0NDI1Mg==&mid=2247570306&idx=3&sn=4709b742087bda1588b514d490e61649&poc_token=HOTDz2ijn2kPiGuS4XsfZnRVA7Ck9v8YVRsAtHXH
https://blog.csdn.net/m0_61789994/article/details/130696338

markdown 以及 latex 公式：
https://zhuanlan.zhihu.com/p/450465546